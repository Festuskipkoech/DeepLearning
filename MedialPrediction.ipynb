{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkFZM+J7uyb0RrfrRcDdMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Festuskipkoech/DeepLearning/blob/main/MedialPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q74wx2zqA0og"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Dense,Embedding, Flatten, concatenate, Dropout, BatchNormalization, GlobalAveragePooling2D)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seeds for productivity\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "-vNVQBMMNChg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate synthetic data\n",
        "def generate_synthetic_data(n_samples=1000):\n",
        "  # dummy data\n",
        "  images = np.random.rand(n_samples, 224, 224, 3)\n",
        "\n",
        "  # generate the data in tabular form\n",
        "  tabular_data = pd.DataFrame({\n",
        "      'age':np.random.normal(60, 15, n_samples),\n",
        "      'gender':np.random.choice(['M', 'F'], n_samples),\n",
        "      'smoking_status':np.random.choice(['Never', 'Former', 'Current'], n_samples),\n",
        "      'blood_pressure':np.random.normal(130, 20, n_samples),\n",
        "      'cholestrol':np.random.normal(200, 40, n_samples),\n",
        "      'bmi':np.random.normal(25, 5, n_samples)\n",
        "  })\n",
        "  # synthetic labels\n",
        "  labels= np.random.binomial(1, 0.3, n_samples)\n",
        "  return images, tabular_data, labels\n"
      ],
      "metadata": {
        "id": "5IWoyZ7SOU-v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process tabular data\n",
        "def process_tabular_data(df):\n",
        "  df_processed =df.copy()\n",
        "\n",
        "  # initialize dict to store preprocessed objects\n",
        "  label_encoders={}\n",
        "  numerical_scaler = StandardScaler()\n",
        "\n",
        "  # categorical columns\n",
        "  categorical_cols = ['gender', 'smoking_status']\n",
        "  numerical_cols = ['age', 'blood_pressure', 'cholestrol', 'bmi']\n",
        "\n",
        "  # label encode categorical varible\n",
        "  for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df_processed[col] = label_encoders[col].fit_transform(df_processed[col])\n",
        "  df_processed[numerical_cols] = numerical_scaler.fit_transform(df_processed[numerical_cols])\n",
        "  return df_processed, label_encoders, numerical_scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "731hlDQOQ77D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import DEBUG\n",
        "# create multi model modal\n",
        "def create_multilmodal_model(image_shape, num_numerical_vars, categorical_cardinalities):\n",
        "  # image stream\n",
        "  image_input = Input(shape = image_shape)\n",
        "  base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "\n",
        "  x_img = GlobalAveragePooling2D()(base_model.output)\n",
        "  x_img = Dense(512, activation='relu')(x_img)\n",
        "  x_img =BatchNormalization()(x_img)\n",
        "  x_img =Dense(256, activation='relu')(x_img)\n",
        "\n",
        "  # tabular stream -categorical\n",
        "  categorical_inputs =[]\n",
        "  categorical_embeddings =[]\n",
        "\n",
        "  for cardinality in categorical_cardinalities:\n",
        "   input_cat = Input(shape=(1,))\n",
        "   embedding_size = min(50, cardinality // 2)\n",
        "   embedding = Embedding(cardinality, embedding_size)(input_cat)\n",
        "   embedding = Flatten()(embedding)\n",
        "   categorical_embeddings.append(embedding)\n",
        "\n",
        "  # tabular stream-numerical\n",
        "  numerical_input = Input(shape=(num_numerical_vars,))\n",
        "  x_num = BatchNormalization()(numerical_input)\n",
        "\n",
        "  # combine categorical and numerical\n",
        "  x_tab =concatenate(categorical_embeddings + [x_num])\n",
        "  x_tab = Dense (256, activation='relu')(x_tab)\n",
        "  x_tab = Dense(128, activation='relu')(x_tab)\n",
        "\n",
        "  # merge streams\n",
        "  merged = concatenate([x_img, x_tab])\n",
        "  x = Dense(256, activation='relu')(merged)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(128, activation='relu')(x)\n",
        "  x= Dropout(0.3)(x)\n",
        "\n",
        "  # output\n",
        "  output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  # create model\n",
        "  model =Model(inputs=[image_input] + categorical_inputs + [numerical_input], outputs=output)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cshAtCFKTg-B"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}