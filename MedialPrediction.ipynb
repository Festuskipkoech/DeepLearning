{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnOtYUZjrTsVQiH7GhcBDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Festuskipkoech/DeepLearning/blob/main/MedialPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q74wx2zqA0og"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Dense,Embedding, Flatten, concatenate, Dropout, BatchNormalization, GlobalAveragePooling2D)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seeds for productivity\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "-vNVQBMMNChg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate synthetic data\n",
        "def generate_synthetic_data(n_samples=1000):\n",
        "  # dummy data\n",
        "  images = np.random.rand(n_samples, 224, 224, 3)\n",
        "\n",
        "  # generate the data in tabular form\n",
        "  tabular_data = pd.DataFrame({\n",
        "      'age':np.random.normal(60, 15, n_samples),\n",
        "      'gender':np.random.choice(['M', 'F'], n_samples),\n",
        "      'smoking_status':np.random.choice(['Never', 'Former', 'Current'], n_samples),\n",
        "      'blood_pressure':np.random.normal(130, 20, n_samples),\n",
        "      'cholestrol':np.random.normal(200, 40, n_samples),\n",
        "      'bmi':np.random.normal(25, 5, n_samples)\n",
        "  })\n",
        "  # synthetic labels\n",
        "  labels= np.random.binomial(1, 0.3, n_samples)\n",
        "  return images, tabular_data, labels\n"
      ],
      "metadata": {
        "id": "5IWoyZ7SOU-v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process tabular data\n",
        "def preprocess_tabular_data(df):\n",
        "  df_processed =df.copy()\n",
        "\n",
        "  # initialize dict to store preprocessed objects\n",
        "  label_encoders={}\n",
        "  numerical_scaler = StandardScaler()\n",
        "\n",
        "  # categorical columns\n",
        "  categorical_cols = ['gender', 'smoking_status']\n",
        "  numerical_cols = ['age', 'blood_pressure', 'cholestrol', 'bmi']\n",
        "\n",
        "  # label encode categorical varible\n",
        "  for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df_processed[col] = label_encoders[col].fit_transform(df_processed[col])\n",
        "  df_processed[numerical_cols] = numerical_scaler.fit_transform(df_processed[numerical_cols])\n",
        "  return df_processed, label_encoders, numerical_scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "731hlDQOQ77D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import DEBUG\n",
        "# create multi model modal\n",
        "def create_multilmodal_model(image_shape, num_numerical_vars, categorical_cardinalities):\n",
        "  # image stream\n",
        "  image_input = Input(shape = image_shape)\n",
        "  base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "\n",
        "  x_img = GlobalAveragePooling2D()(base_model.output)\n",
        "  x_img = Dense(512, activation='relu')(x_img)\n",
        "  x_img =BatchNormalization()(x_img)\n",
        "  x_img =Dense(256, activation='relu')(x_img)\n",
        "\n",
        "  # tabular stream -categorical\n",
        "  categorical_inputs =[]\n",
        "  categorical_embeddings =[]\n",
        "\n",
        "  for cardinality in categorical_cardinalities:\n",
        "    input_cat = Input(shape=(1,)) # Create Input layer for each categorical feature\n",
        "    categorical_inputs.append(input_cat) # Append the Input layer to categorical_inputs\n",
        "    embedding_size = min(50, cardinality // 2)\n",
        "    embedding = Embedding(cardinality, embedding_size)(input_cat)\n",
        "    embedding = Flatten()(embedding)\n",
        "    categorical_embeddings.append(embedding)\n",
        "\n",
        "  # tabular stream-numerical\n",
        "  numerical_input = Input(shape=(num_numerical_vars,))\n",
        "  x_num = BatchNormalization()(numerical_input)\n",
        "\n",
        "  # combine categorical and numerical\n",
        "  x_tab =concatenate(categorical_embeddings + [x_num])\n",
        "  x_tab = Dense (256, activation='relu')(x_tab)\n",
        "  x_tab = Dense(128, activation='relu')(x_tab)\n",
        "\n",
        "  # merge streams\n",
        "  merged = concatenate([x_img, x_tab])\n",
        "  x = Dense(256, activation='relu')(merged)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(128, activation='relu')(x)\n",
        "  x= Dropout(0.3)(x)\n",
        "\n",
        "  # output\n",
        "  output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  # create model\n",
        "  model =Model(inputs=[image_input] + categorical_inputs + [numerical_input], outputs=output)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cshAtCFKTg-B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and evaluation\n",
        "def train_model(model, train_data, val_data, epochs=10, batch_size=32):\n",
        "  # unpack training data\n",
        "  (X_train_img, X_train_cat_list, X_train_num), y_train =train_data\n",
        "  (X_val_img, X_val_cat_list, X_val_num), y_val = val_data\n",
        "\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer ='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics = ['accuracy', tf.keras.metrics.AUC()]\n",
        "  )\n",
        "\n",
        "  # create data generators for image augmentation\n",
        "  image_datagen = ImageDataGenerator(\n",
        "      rotation_range = 15,\n",
        "      width_shift_range = 0.1,\n",
        "      height_shift_range = 0.1,\n",
        "      zoom_range = 0.1,\n",
        "      horizontal_flip = True\n",
        "  )\n",
        "\n",
        "  # train model\n",
        "  history = model.fit(\n",
        "      [X_train_img] + X_train_cat_list + [X_train_num],\n",
        "      y_train,\n",
        "      validation_data = ([X_val_img] + X_val_cat_list + [X_val_num], y_val),\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  return history"
      ],
      "metadata": {
        "id": "nfudZjstY-WT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "def plot_training_history(history):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "  # plot loss\n",
        "  ax1.plot(history.history['loss'], label='Training loss')\n",
        "  ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  ax1.set_title('Model Loss')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.legend()\n",
        "\n",
        "  # plot accuracy\n",
        "  ax2.plot(history.history['accuracy'], label='Training accuracy')\n",
        "  ax2.plot(history.history['val_accuracy'], label='Validatin accuracy')\n",
        "  ax2.set_title('Model Accuracy')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "T2KlF2SHb_Vh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execution\n",
        "if __name__ == \"__main__\":\n",
        "  # generate synthetic data\n",
        "  images, tabular_data, labels = generate_synthetic_data(1000)\n",
        "  # preprocess tabular data\n",
        "  processed_tabular, label_encoders, numerical_scaler = preprocess_tabular_data(tabular_data)\n",
        "  # split categorical and numerical features\n",
        "  categorical_cols = ['gender', 'smoking_status'] # Corrected typo here: 'smoking_status'\n",
        "  numerical_cols = ['age', 'blood_pressure', 'cholestrol', 'bmi']\n",
        "\n",
        "  categorical_data = [processed_tabular[col].values.reshape(-1, 1) for col in categorical_cols]\n",
        "  numerical_data = processed_tabular[numerical_cols].values\n",
        "  # get cardinalities  for categorical variables\n",
        "  categorical_cardinalities = [len(label_encoders[col].classes_) for col in categorical_cols]\n",
        "\n",
        "  # split data\n",
        "  indices = np.arange(len(images))\n",
        "  train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "  # prepare training data\n",
        "  X_train_img = images[train_idx]\n",
        "  X_train_cat = [data[train_idx] for  data in categorical_data]\n",
        "  X_train_num = numerical_data[train_idx] # Use indexing with brackets []\n",
        "  y_train = labels[train_idx] # Use indexing with brackets []\n",
        "\n",
        "  # prepare validation data\n",
        "  X_val_img = images[val_idx]\n",
        "  X_val_cat = [data[val_idx] for data in categorical_data]\n",
        "  X_val_num = numerical_data[val_idx] # Use indexing with brackets []\n",
        "  y_val = labels[val_idx] # Use indexing with brackets []\n",
        "\n",
        "  # create and train model\n",
        "  model = create_multilmodal_model(\n",
        "      image_shape=(224, 224, 3),\n",
        "      num_numerical_vars=len(numerical_cols),\n",
        "      categorical_cardinalities=categorical_cardinalities\n",
        "      )\n",
        "  # train model\n",
        "  history = train_model(\n",
        "      model,\n",
        "      ((X_train_img, X_train_cat, X_train_num), y_train),\n",
        "      ((X_val_img, X_val_cat, X_val_num), y_val),\n",
        "      epochs=20\n",
        "\n",
        "  )\n",
        "  plot_training_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaXJ8ivXeXyV",
        "outputId": "76a137ae-bcb7-4692-f394-6d0ef83a0ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 26s/step - accuracy: 0.6185 - auc: 0.4378 - loss: 0.7123 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 7.9104\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 26s/step - accuracy: 0.7050 - auc: 0.5235 - loss: 0.6207 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 8704.0430\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 26s/step - accuracy: 0.7063 - auc: 0.5569 - loss: 0.6094 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 245.2263\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 26s/step - accuracy: 0.7096 - auc: 0.5375 - loss: 0.6234 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 552.3369\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 26s/step - accuracy: 0.7222 - auc: 0.6766 - loss: 0.5741 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 54.7027\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 25s/step - accuracy: 0.7719 - auc: 0.7719 - loss: 0.4998 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 17.0767\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 26s/step - accuracy: 0.8542 - auc: 0.8470 - loss: 0.4226 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 36.9080\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 26s/step - accuracy: 0.8743 - auc: 0.9210 - loss: 0.3236 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 33.0019\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 25s/step - accuracy: 0.9019 - auc: 0.9363 - loss: 0.2647 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 13.6035\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 26s/step - accuracy: 0.9385 - auc: 0.9676 - loss: 0.1829 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 12.2279\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 26s/step - accuracy: 0.9571 - auc: 0.9740 - loss: 0.1556 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 3.7165\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 26s/step - accuracy: 0.9568 - auc: 0.9918 - loss: 0.1143 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 63.7075\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 26s/step - accuracy: 0.9643 - auc: 0.9924 - loss: 0.0999 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 43.2171\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 26s/step - accuracy: 0.9785 - auc: 0.9976 - loss: 0.0689 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 53.0383\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 26s/step - accuracy: 0.9770 - auc: 0.9932 - loss: 0.0811 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 35.7639\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 26s/step - accuracy: 0.9850 - auc: 0.9983 - loss: 0.0578 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 16.8246\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 26s/step - accuracy: 0.9889 - auc: 0.9999 - loss: 0.0228 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 21.1467\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 26s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0034 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 16.2880\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 26s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0010 - val_accuracy: 0.7100 - val_auc: 0.5000 - val_loss: 12.5339\n",
            "Epoch 20/20\n",
            "\u001b[1m12/25\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 24s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 6.9567e-04"
          ]
        }
      ]
    }
  ]
}